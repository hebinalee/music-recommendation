import os
import json
import numpy as np
import pandas as pd
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
from .vector_database import MusicVectorDatabase
from .spotify_collector import SpotifyMusicCollector

import torch
import torch.nn as nn
import torch.nn.functional as F
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import StandardScaler, LabelEncoder
from .ann_index import ANNIndex

class MusicRecommender:
    def __init__(self, vector_db: MusicVectorDatabase, spotify_collector: SpotifyMusicCollector):
        """ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.vector_db = vector_db
        self.spotify_collector = spotify_collector
        self.user_preferences = {}
        
        # Two-stage ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        load_dotenv()
        self.model_save_dir = os.getenv('MODEL_SAVE_DIR', './models')
        self.embedding_dim = int(os.getenv('EMBEDDING_DIM', '128'))
        self.hidden_dim = int(os.getenv('HIDDEN_DIM', '256'))
        self.learning_rate = float(os.getenv('LEARNING_RATE', '0.001'))
        self.batch_size = int(os.getenv('BATCH_SIZE', '32'))
        self.epochs = int(os.getenv('EPOCHS', '100'))
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.model_save_dir, exist_ok=True)
        
        # Two-Tower ëª¨ë¸ (í›„ë³´ ìƒì„±ìš©)
        self.two_tower_model = None
        self.user_encoder = None
        self.item_encoder = None
        
        # Wide&Deep ëª¨ë¸ (ë­í‚¹ìš©)
        self.wide_deep_model = None
        
        # ë°ì´í„° ì „ì²˜ë¦¬ê¸°
        self.user_scaler = StandardScaler()
        self.item_scaler = StandardScaler()
        self.user_encoder = LabelEncoder()
        self.item_encoder = LabelEncoder()
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„
        self._load_models()
        
        # ANN ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.ann_index = ANNIndex(self.embedding_dim, 
                                   index_path=os.path.join(self.model_save_dir, 'faiss_index.bin'),
                                   mapping_path=os.path.join(self.model_save_dir, 'faiss_id_map.json'))
        self.ann_index.load()
    
    def _load_models(self):
        """ì €ì¥ëœ ëª¨ë¸ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # Two-Tower ëª¨ë¸ ë¡œë“œ
            two_tower_path = os.path.join(self.model_save_dir, 'two_tower_model.pth')
            if os.path.exists(two_tower_path):
                self.two_tower_model = TwoTowerModel(self.embedding_dim, self.hidden_dim)
                self.two_tower_model.load_state_dict(torch.load(two_tower_path))
                self.two_tower_model.eval()
                print("âœ… Two-Tower ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # Wide&Deep ëª¨ë¸ ë¡œë“œ
            wide_deep_path = os.path.join(self.model_save_dir, 'wide_deep_model')
            if os.path.exists(wide_deep_path):
                self.wide_deep_model = tf.keras.models.load_model(wide_deep_path)
                print("âœ… Wide&Deep ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    
    def add_user_preference(self, user_id: str, track_id: str, rating: float = 1.0):
        """ì‚¬ìš©ìì˜ ìŒì•… ì„ í˜¸ë„ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {}
        
        self.user_preferences[user_id][track_id] = rating
        print(f"Added preference for user {user_id}: track {track_id} with rating {rating}")
    
    def get_user_profile(self, user_id: str) -> Dict[str, float]:
        """ì‚¬ìš©ìì˜ ìŒì•… í”„ë¡œí•„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if user_id not in self.user_preferences:
            return {}
        
        # ì‚¬ìš©ìê°€ í‰ê°€í•œ íŠ¸ë™ë“¤ì˜ ì˜¤ë””ì˜¤ íŠ¹ì„± í‰ê·  ê³„ì‚°
        user_tracks = self.user_preferences[user_id]
        audio_features = []
        weights = []
        
        for track_id, rating in user_tracks.items():
            # íŠ¸ë™ì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ
            track_data = self.vector_db.collection.get(ids=[track_id])
            if track_data['metadatas']:
                metadata = track_data['metadatas'][0]
                features = {}
                
                # ì˜¤ë””ì˜¤ íŠ¹ì„± ìˆ˜ì§‘
                audio_feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                                     'instrumentalness', 'acousticness', 'liveness', 'speechiness']
                
                for feature in audio_feature_names:
                    if feature in metadata:
                        features[feature] = metadata[feature]
                
                if features:
                    audio_features.append(features)
                    weights.append(rating)
        
        if not audio_features:
            return {}
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        user_profile = {}
        for feature in audio_features[0].keys():
            weighted_sum = sum(features[feature] * weight for features, weight in zip(audio_features, weights))
            total_weight = sum(weights)
            user_profile[feature] = weighted_sum / total_weight
        
        return user_profile
    
    def recommend_music(self, user_id: str, n_recommendations: int = 10, 
                       method: str = 'hybrid') -> List[Dict[str, Any]]:
        """ì‚¬ìš©ìì—ê²Œ ìŒì•…ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
        if method == 'two_stage':
            return self._two_stage_recommendation(user_id, n_recommendations)
        elif method == 'collaborative':
            return self._collaborative_filtering(user_id, n_recommendations)
        elif method == 'content_based':
            return self._content_based_filtering(user_id, n_recommendations)
        elif method == 'hybrid':
            return self._hybrid_recommendation(user_id, n_recommendations)
        else:
            raise ValueError("Method must be 'two_stage', 'collaborative', 'content_based', or 'hybrid'")
    
    def _content_based_filtering(self, user_id: str, n_recommendations: int) -> List[Dict[str, Any]]:
        """ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ì„ ì‚¬ìš©í•œ ì¶”ì²œ"""
        user_profile = self.get_user_profile(user_id)
        
        if not user_profile:
            return []
        
        # ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ìœ ì‚¬í•œ ì˜¤ë””ì˜¤ íŠ¹ì„±ì„ ê°€ì§„ ìŒì•… ê²€ìƒ‰
        recommendations = self.vector_db.search_by_audio_features(
            user_profile, n_results=n_recommendations
        )
        
        # ì´ë¯¸ ì‚¬ìš©ìê°€ í‰ê°€í•œ íŠ¸ë™ì€ ì œì™¸
        user_rated_tracks = set(self.user_preferences.get(user_id, {}).keys())
        filtered_recommendations = [
            rec for rec in recommendations 
            if rec['id'] not in user_rated_tracks
        ]
        
        return filtered_recommendations[:n_recommendations]
    
    def _collaborative_filtering(self, user_id: str, n_recommendations: int) -> List[Dict[str, Any]]:
        """í˜‘ì—… í•„í„°ë§ì„ ì‚¬ìš©í•œ ì¶”ì²œ"""
        if user_id not in self.user_preferences:
            return []
        
        # ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        user_similarities = {}
        current_user_tracks = set(self.user_preferences[user_id].keys())
        
        for other_user_id, other_preferences in self.user_preferences.items():
            if other_user_id == user_id:
                continue
            
            other_user_tracks = set(other_preferences.keys())
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(current_user_tracks & other_user_tracks)
            union = len(current_user_tracks | other_user_tracks)
            
            if union > 0:
                similarity = intersection / union
                user_similarities[other_user_id] = similarity
        
        # ìœ ì‚¬ë„ê°€ ë†’ì€ ì‚¬ìš©ìë“¤ì˜ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
        recommendations = {}
        
        for other_user_id, similarity in sorted(user_similarities.items(), 
                                              key=lambda x: x[1], reverse=True)[:5]:
            other_preferences = self.user_preferences[other_user_id]
            
            for track_id, rating in other_preferences.items():
                if track_id not in current_user_tracks:
                    if track_id not in recommendations:
                        recommendations[track_id] = 0
                    recommendations[track_id] += similarity * rating
        
        # ì¶”ì²œ ì ìˆ˜ë¡œ ì •ë ¬
        sorted_recommendations = sorted(recommendations.items(), 
                                      key=lambda x: x[1], reverse=True)
        
        # ìƒìœ„ ì¶”ì²œ ê²°ê³¼ ë°˜í™˜
        top_recommendations = []
        for track_id, score in sorted_recommendations[:n_recommendations]:
            track_data = self.vector_db.collection.get(ids=[track_id])
            if track_data['metadatas']:
                metadata = track_data['metadatas'][0]
                recommendation = {
                    'id': track_id,
                    'name': metadata['name'],
                    'artists': metadata['artists'],
                    'album': metadata['album'],
                    'recommendation_score': score,
                    'metadata': metadata
                }
                top_recommendations.append(recommendation)
        
        return top_recommendations
    
    def _hybrid_recommendation(self, user_id: str, n_recommendations: int) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (ì½˜í…ì¸  ê¸°ë°˜ + í˜‘ì—… í•„í„°ë§)"""
        content_based = self._content_based_filtering(user_id, n_recommendations // 2)
        collaborative = self._collaborative_filtering(user_id, n_recommendations // 2)
        
        # ê²°ê³¼ ë³‘í•© ë° ì •ë ¬
        all_recommendations = []
        
        for rec in content_based:
            rec['method'] = 'content_based'
            all_recommendations.append(rec)
        
        for rec in collaborative:
            rec['method'] = 'collaborative'
            all_recommendations.append(rec)
        
        # ì¤‘ë³µ ì œê±° (ID ê¸°ì¤€)
        unique_recommendations = {}
        for rec in all_recommendations:
            if rec['id'] not in unique_recommendations:
                unique_recommendations[rec['id']] = rec
            else:
                # ì¤‘ë³µëœ ê²½ìš° ì ìˆ˜ í‰ê· 
                existing = unique_recommendations[rec['id']]
                if 'recommendation_score' in existing and 'feature_score' in rec:
                    existing['hybrid_score'] = (existing.get('recommendation_score', 0) + 
                                              (1.0 / (1.0 + rec['feature_score']))) / 2
                elif 'feature_score' in existing and 'recommendation_score' in rec:
                    existing['hybrid_score'] = (existing['feature_score'] + 
                                              rec['recommendation_score']) / 2
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬
        final_recommendations = list(unique_recommendations.values())
        final_recommendations.sort(key=lambda x: x.get('hybrid_score', 0) or x.get('feature_score', 0) or x.get('recommendation_score', 0), reverse=True)
        
        return final_recommendations[:n_recommendations]
    
    def _two_stage_recommendation(self, user_id: str, n_recommendations: int) -> List[Dict[str, Any]]:
        """Two-stage ì¶”ì²œ ì‹œìŠ¤í…œ: Two-Towerë¡œ í›„ë³´ ìƒì„±, Wide&Deepìœ¼ë¡œ ë­í‚¹"""
        try:
            # Stage 1: Two-Tower ëª¨ë¸ë¡œ í›„ë³´ ìƒì„± (ë” ë§ì€ í›„ë³´ ìƒì„±)
            candidate_count = min(n_recommendations * 10, 1000)  # ì¶©ë¶„í•œ í›„ë³´ ìƒì„±
            candidates = self._generate_candidates_two_tower(user_id, candidate_count)
            
            if not candidates:
                print("âš ï¸ Two-Tower ëª¨ë¸ë¡œ í›„ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self._hybrid_recommendation(user_id, n_recommendations)
            
            # Stage 2: Wide&Deep ëª¨ë¸ë¡œ ë­í‚¹
            ranked_candidates = self._rank_candidates_wide_deep(user_id, candidates)
            
            # ìƒìœ„ ê²°ê³¼ ë°˜í™˜
            final_recommendations = []
            for candidate in ranked_candidates[:n_recommendations]:
                track_data = self.vector_db.collection.get(ids=[candidate['id']])
                if track_data['metadatas']:
                    metadata = track_data['metadatas'][0]
                    recommendation = {
                        'id': candidate['id'],
                        'name': metadata['name'],
                        'artists': metadata['artists'],
                        'album': metadata['album'],
                        'two_stage_score': candidate['score'],
                        'method': 'two_stage',
                        'metadata': metadata
                    }
                    final_recommendations.append(recommendation)
            
            return final_recommendations
            
        except Exception as e:
            print(f"âŒ Two-stage ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ê¸°ë³¸ í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return self._hybrid_recommendation(user_id, n_recommendations)
    
    def _generate_candidates_two_tower(self, user_id: str, n_candidates: int) -> List[Dict[str, Any]]:
        """Two-Tower ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í›„ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if self.two_tower_model is None:
                print("âš ï¸ Two-Tower ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.")
                self._train_two_tower_model()
            
            # ì‚¬ìš©ì ì„ë² ë”© ìƒì„±
            user_embedding = self._get_user_embedding(user_id)
            if user_embedding is None:
                return []
            
            # ANN ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¹Œë“œ ì‹œë„
            if not self.ann_index.is_ready():
                self._rebuild_ann_index()
                if not self.ann_index.is_ready():
                    print("âš ï¸ ANN ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì „ìˆ˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    return self._fallback_bruteforce_candidates(user_embedding, n_candidates)
            
            # ANN ê²€ìƒ‰
            user_vec = user_embedding.detach().cpu().numpy().reshape(1, -1)
            scores, ids = self.ann_index.search(user_vec, n_candidates)
            decoded_ids = self.ann_index.decode_ids(ids)
            results = []
            for i, item_id in enumerate(decoded_ids[0]):
                if not item_id:
                    continue
                results.append({'id': item_id, 'similarity': float(scores[0][i])})
            return results
        except Exception as e:
            print(f"âŒ Two-Tower í›„ë³´ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _fallback_bruteforce_candidates(self, user_embedding: torch.Tensor, n_candidates: int) -> List[Dict[str, Any]]:
        all_items = self.vector_db.collection.get()
        if not all_items['ids']:
            return []
        similarities = []
        for item_id in all_items['ids']:
            item_embedding = self._get_item_embedding(item_id)
            if item_embedding is None:
                continue
            similarity = F.cosine_similarity(user_embedding.unsqueeze(0), item_embedding.unsqueeze(0)).item()
            similarities.append({'id': item_id, 'similarity': similarity})
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        return similarities[:n_candidates]
    
    def _rank_candidates_wide_deep(self, user_id: str, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Wide&Deep ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í›„ë³´ë“¤ì„ ë­í‚¹í•©ë‹ˆë‹¤."""
        try:
            if self.wide_deep_model is None:
                print("âš ï¸ Wide&Deep ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.")
                self._train_wide_deep_model()
            
            # ì‚¬ìš©ìê°€ ì´ë¯¸ í‰ê°€í•œ íŠ¸ë™ì€ ì œì™¸
            user_rated_tracks = set(self.user_preferences.get(user_id, {}).keys())
            filtered_candidates = [c for c in candidates if c['id'] not in user_rated_tracks]
            
            if not filtered_candidates:
                return candidates
            
            # Wide&Deep ëª¨ë¸ë¡œ ì ìˆ˜ ì˜ˆì¸¡
            ranked_candidates = []
            for candidate in filtered_candidates:
                score = self._predict_wide_deep_score(user_id, candidate['id'])
                ranked_candidates.append({
                    'id': candidate['id'],
                    'score': score,
                    'similarity': candidate['similarity']
                })
            
            # ì ìˆ˜ë¡œ ì •ë ¬
            ranked_candidates.sort(key=lambda x: x['score'], reverse=True)
            return ranked_candidates
            
        except Exception as e:
            print(f"âŒ Wide&Deep ë­í‚¹ ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ìœ ì‚¬ë„ë¡œ ì •ë ¬
            return sorted(candidates, key=lambda x: x['similarity'], reverse=True)
    
    def _get_user_embedding(self, user_id: str) -> Optional[torch.Tensor]:
        """ì‚¬ìš©ìì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            user_profile = self.get_user_profile(user_id)
            if not user_profile:
                return None
            
            # ì‚¬ìš©ì íŠ¹ì„±ì„ í…ì„œë¡œ ë³€í™˜
            user_features = []
            feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                           'instrumentalness', 'acousticness', 'liveness', 'speechiness']
            
            for feature in feature_names:
                if feature in user_profile:
                    user_features.append(user_profile[feature])
                else:
                    user_features.append(0.0)
            
            user_tensor = torch.tensor(user_features, dtype=torch.float32)
            
            # Two-Tower ëª¨ë¸ì˜ ì‚¬ìš©ì ì¸ì½”ë”ë¥¼ í†µê³¼
            if self.two_tower_model:
                with torch.no_grad():
                    user_embedding = self.two_tower_model.user_tower(user_tensor.unsqueeze(0))
                    return user_embedding.squeeze(0)
            
            return None
            
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _get_item_embedding(self, item_id: str) -> Optional[torch.Tensor]:
        """ì•„ì´í…œì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            item_data = self.vector_db.collection.get(ids=[item_id])
            if not item_data['metadatas']:
                return None
            
            metadata = item_data['metadatas'][0]
            
            # ì•„ì´í…œ íŠ¹ì„±ì„ í…ì„œë¡œ ë³€í™˜
            item_features = []
            feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                           'instrumentalness', 'acousticness', 'liveness', 'speechiness']
            
            for feature in feature_names:
                if feature in metadata:
                    item_features.append(metadata[feature])
                else:
                    item_features.append(0.0)
            
            item_tensor = torch.tensor(item_features, dtype=torch.float32)
            
            # Two-Tower ëª¨ë¸ì˜ ì•„ì´í…œ ì¸ì½”ë”ë¥¼ í†µê³¼
            if self.two_tower_model:
                with torch.no_grad():
                    item_embedding = self.two_tower_model.item_tower(item_tensor.unsqueeze(0))
                    return item_embedding.squeeze(0)
            
            return None
            
        except Exception as e:
            print(f"âŒ ì•„ì´í…œ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _predict_wide_deep_score(self, user_id: str, item_id: str) -> float:
        """Wide&Deep ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
        try:
            # ì‚¬ìš©ì íŠ¹ì„±
            user_profile = self.get_user_profile(user_id)
            user_features = []
            feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                           'instrumentalness', 'acousticness', 'liveness', 'speechiness']
            
            for feature in feature_names:
                if feature in user_profile:
                    user_features.append(user_profile[feature])
                else:
                    user_features.append(0.0)
            
            # ì•„ì´í…œ íŠ¹ì„±
            item_data = self.vector_db.collection.get(ids=[item_id])
            if not item_data['metadatas']:
                return 0.0
            
            metadata = item_data['metadatas'][0]
            item_features = []
            
            for feature in feature_names:
                if feature in metadata:
                    item_features.append(metadata[feature])
                else:
                    item_features.append(0.0)
            
            # íŠ¹ì„± ê²°í•©
            combined_features = user_features + item_features
            
            # ëª¨ë¸ ì˜ˆì¸¡
            if self.wide_deep_model:
                prediction = self.wide_deep_model.predict(
                    np.array([combined_features]), verbose=0
                )
                return float(prediction[0][0])
            
            return 0.0
            
        except Exception as e:
            print(f"âŒ Wide&Deep ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _train_two_tower_model(self):
        """Two-Tower ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤."""
        try:
            print("ğŸ”„ Two-Tower ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # ëª¨ë¸ ìƒì„±
            self.two_tower_model = TwoTowerModel(self.embedding_dim, self.hidden_dim)
            
            # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
            train_data = self._prepare_two_tower_training_data()
            if not train_data:
                print("âŒ í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return
            
            # í›ˆë ¨ ì„¤ì •
            optimizer = torch.optim.Adam(self.two_tower_model.parameters(), lr=self.learning_rate)
            criterion = nn.BCEWithLogitsLoss()
            
            # í›ˆë ¨ ë£¨í”„
            self.two_tower_model.train()
            for epoch in range(self.epochs):
                total_loss = 0
                for batch in train_data:
                    user_features, item_features, labels = batch
                    
                    optimizer.zero_grad()
                    outputs = self.two_tower_model(user_features, item_features)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                if (epoch + 1) % 10 == 0:
                    print(f"Epoch [{epoch+1}/{self.epochs}], Loss: {total_loss/len(train_data):.4f}")
            
            # ëª¨ë¸ ì €ì¥
            model_path = os.path.join(self.model_save_dir, 'two_tower_model.pth')
            torch.save(self.two_tower_model.state_dict(), model_path)
            print(f"âœ… Two-Tower ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ë° ì €ì¥: {model_path}")
            # ëª¨ë¸ì´ ê°±ì‹ ë˜ì—ˆìœ¼ë¯€ë¡œ ANN ì¸ë±ìŠ¤ ì¬ë¹Œë“œ
            self._rebuild_ann_index()
            
        except Exception as e:
            print(f"âŒ Two-Tower ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")

    def _rebuild_ann_index(self) -> None:
        try:
            # ëª¨ë“  ì•„ì´í…œ ì„ë² ë”© ê³„ì‚°
            all_items = self.vector_db.collection.get()
            if not all_items['ids']:
                return
            item_ids: List[str] = []
            item_emb_list: List[np.ndarray] = []
            for item_id in all_items['ids']:
                emb = self._get_item_embedding(item_id)
                if emb is None:
                    continue
                item_ids.append(item_id)
                item_emb_list.append(emb.detach().cpu().numpy())
            if not item_emb_list:
                return
            item_emb_matrix = np.vstack(item_emb_list)
            self.ann_index.build_from_embeddings(item_ids, item_emb_matrix, use_ivf=False)
            # IVFê°€ í•„ìš”í•œ ëŒ€ê·œëª¨ì¼ ê²½ìš° use_ivf=Trueë¡œ ì „í™˜ ê°€ëŠ¥
            self.ann_index.save()
            print(f"âœ… ANN index built with {len(item_ids)} items")
        except Exception as e:
            print(f"âŒ ANN ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤íŒ¨: {e}")
    
    def _train_wide_deep_model(self):
        """Wide&Deep ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤."""
        try:
            print("ğŸ”„ Wide&Deep ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
            train_data = self._prepare_wide_deep_training_data()
            if not train_data:
                print("âŒ í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return
            
            # ëª¨ë¸ ìƒì„±
            input_dim = len(train_data[0][0])  # íŠ¹ì„± ì°¨ì›
            self.wide_deep_model = self._build_wide_deep_model(input_dim)
            
            # í›ˆë ¨
            X, y = zip(*train_data)
            X = np.array(X)
            y = np.array(y)
            
            history = self.wide_deep_model.fit(
                X, y,
                epochs=self.epochs,
                batch_size=self.batch_size,
                validation_split=0.2,
                verbose=1
            )
            
            # ëª¨ë¸ ì €ì¥
            model_path = os.path.join(self.model_save_dir, 'wide_deep_model')
            self.wide_deep_model.save(model_path)
            print(f"âœ… Wide&Deep ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ë° ì €ì¥: {model_path}")
            
        except Exception as e:
            print(f"âŒ Wide&Deep ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _prepare_two_tower_training_data(self):
        """Two-Tower ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        try:
            training_data = []
            
            # ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„° ìƒì„±
            for user_id, preferences in self.user_preferences.items():
                user_profile = self.get_user_profile(user_id)
                if not user_profile:
                    continue
                
                for item_id, rating in preferences.items():
                    item_data = self.vector_db.collection.get(ids=[item_id])
                    if not item_data['metadatas']:
                        continue
                    
                    metadata = item_data['metadatas'][0]
                    
                    # ì‚¬ìš©ì íŠ¹ì„±
                    user_features = []
                    feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                                   'instrumentalness', 'acousticness', 'liveness', 'speechiness']
                    
                    for feature in feature_names:
                        if feature in user_profile:
                            user_features.append(user_profile[feature])
                        else:
                            user_features.append(0.0)
                    
                    # ì•„ì´í…œ íŠ¹ì„±
                    item_features = []
                    for feature in feature_names:
                        if feature in metadata:
                            item_features.append(metadata[feature])
                        else:
                            item_features.append(0.0)
                    
                    # ê¸ì •ì  ìƒ˜í”Œ (rating >= 3.0)
                    if rating >= 3.0:
                        training_data.append((
                            torch.tensor(user_features, dtype=torch.float32),
                            torch.tensor(item_features, dtype=torch.float32),
                            torch.tensor([1.0], dtype=torch.float32)
                        ))
                    
                    # ë¶€ì •ì  ìƒ˜í”Œ (rating < 3.0)
                    if rating < 3.0:
                        training_data.append((
                            torch.tensor(user_features, dtype=torch.float32),
                            torch.tensor(item_features, dtype=torch.float32),
                            torch.tensor([0.0], dtype=torch.float32)
                        ))
            
            return training_data
            
        except Exception as e:
            print(f"âŒ Two-Tower í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _prepare_wide_deep_training_data(self):
        """Wide&Deep ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        try:
            training_data = []
            
            # ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„° ìƒì„±
            for user_id, preferences in self.user_preferences.items():
                user_profile = self.get_user_profile(user_id)
                if not user_profile:
                    continue
                
                for item_id, rating in preferences.items():
                    item_data = self.vector_db.collection.get(ids=[item_id])
                    if not item_data['metadatas']:
                        continue
                    
                    metadata = item_data['metadatas'][0]
                    
                    # ì‚¬ìš©ì íŠ¹ì„±
                    user_features = []
                    feature_names = ['danceability', 'energy', 'valence', 'tempo', 
                                   'instrumentalness', 'acousticness', 'liveness', 'speechiness']
                    
                    for feature in feature_names:
                        if feature in user_profile:
                            user_features.append(user_profile[feature])
                        else:
                            user_features.append(0.0)
                    
                    # ì•„ì´í…œ íŠ¹ì„±
                    item_features = []
                    for feature in feature_names:
                        if feature in metadata:
                            item_features.append(metadata[feature])
                        else:
                            item_features.append(0.0)
                    
                    # íŠ¹ì„± ê²°í•©
                    combined_features = user_features + item_features
                    
                    # ì •ê·œí™”ëœ í‰ì  (0-1 ë²”ìœ„)
                    normalized_rating = min(rating / 5.0, 1.0)
                    
                    training_data.append((combined_features, normalized_rating))
            
            return training_data
            
        except Exception as e:
            print(f"âŒ Wide&Deep í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _build_wide_deep_model(self, input_dim: int):
        """Wide&Deep ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        # Wide ë¶€ë¶„ (ì„ í˜• ëª¨ë¸)
        wide_input = keras.layers.Input(shape=(input_dim,))
        wide_output = keras.layers.Dense(1, activation='linear')(wide_input)
        
        # Deep ë¶€ë¶„ (ì‹ ê²½ë§)
        deep_input = keras.layers.Input(shape=(input_dim,))
        deep_output = keras.layers.Dense(self.hidden_dim, activation='relu')(deep_input)
        deep_output = keras.layers.Dropout(0.3)(deep_output)
        deep_output = keras.layers.Dense(self.hidden_dim // 2, activation='relu')(deep_output)
        deep_output = keras.layers.Dropout(0.3)(deep_output)
        deep_output = keras.layers.Dense(1, activation='sigmoid')(deep_output)
        
        # Wideì™€ Deep ê²°í•©
        combined_output = keras.layers.Add()([wide_output, deep_output])
        final_output = keras.layers.Activation('sigmoid')(combined_output)
        
        model = keras.Model(
            inputs=[wide_input, deep_input],
            outputs=final_output
        )
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def get_recommendation_explanation(self, user_id: str, track_id: str) -> str:
        """ì¶”ì²œ ì´ìœ ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤."""
        if user_id not in self.user_preferences:
            return "ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        user_profile = self.get_user_profile(user_id)
        track_data = self.vector_db.collection.get(ids=[track_id])
        
        if not track_data['metadatas']:
            return "íŠ¸ë™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        metadata = track_data['metadatas'][0]
        explanation_parts = []
        
        # ì˜¤ë””ì˜¤ íŠ¹ì„± ê¸°ë°˜ ì„¤ëª…
        audio_features = ['danceability', 'energy', 'valence', 'acousticness', 'instrumentalness']
        for feature in audio_features:
            if feature in user_profile and feature in metadata:
                user_value = user_profile[feature]
                track_value = metadata[feature]
                
                if abs(user_value - track_value) < 0.2:
                    feature_name = {
                        'danceability': 'ì¶¤ì¶”ê¸° ì¢‹ì€',
                        'energy': 'í™œê¸°ì°¬',
                        'valence': 'ê¸ì •ì ì¸',
                        'acousticness': 'ì–´ì¿ ìŠ¤í‹±í•œ',
                        'instrumentalness': 'ê¸°ì•…ì ì¸'
                    }.get(feature, feature)
                    
                    explanation_parts.append(f"{feature_name} íŠ¹ì„±")
        
        # ì¥ë¥´/ì•„í‹°ìŠ¤íŠ¸ ê¸°ë°˜ ì„¤ëª…
        if 'artists' in metadata:
            user_artists = set()
            for track_id in self.user_preferences[user_id].keys():
                track_info = self.vector_db.collection.get(ids=[track_id])
                if track_info['metadatas']:
                    user_artists.update(track_info['metadatas'][0].get('artists', '').split(', '))
            
            track_artists = set(metadata['artists'].split(', '))
            if user_artists & track_artists:
                explanation_parts.append("ì¢‹ì•„í•˜ëŠ” ì•„í‹°ìŠ¤íŠ¸ì™€ ìœ ì‚¬")
        
        if explanation_parts:
            return f"ì´ ê³¡ì„ ì¶”ì²œí•˜ëŠ” ì´ìœ : {', '.join(explanation_parts)}"
        else:
            return "ìƒˆë¡œìš´ ì¥ë¥´ì˜ ìŒì•…ì„ ì‹œë„í•´ë³´ì„¸ìš”!"
    
    def save_user_preferences(self, filename: str = 'user_preferences.json'):
        """ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.user_preferences, f, ensure_ascii=False, indent=2)
        print(f"User preferences saved to {filename}")
    
    def load_user_preferences(self, filename: str = 'user_preferences.json'):
        """íŒŒì¼ì—ì„œ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.user_preferences = json.load(f)
            print(f"User preferences loaded from {filename}")
        except FileNotFoundError:
            print(f"Preferences file {filename} not found. Starting with empty preferences.")
            self.user_preferences = {}


class TwoTowerModel(nn.Module):
    """Two-Tower ëª¨ë¸: ì‚¬ìš©ìì™€ ì•„ì´í…œì„ ë³„ë„ì˜ ì¸ì½”ë”ë¡œ ì²˜ë¦¬"""
    
    def __init__(self, embedding_dim: int, hidden_dim: int):
        super(TwoTowerModel, self).__init__()
        
        # ì‚¬ìš©ì íƒ€ì›Œ (User Tower)
        self.user_tower = nn.Sequential(
            nn.Linear(8, hidden_dim),  # 8ê°œ ì˜¤ë””ì˜¤ íŠ¹ì„±
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, embedding_dim)
        )
        
        # ì•„ì´í…œ íƒ€ì›Œ (Item Tower)
        self.item_tower = nn.Sequential(
            nn.Linear(8, hidden_dim),  # 8ê°œ ì˜¤ë””ì˜¤ íŠ¹ì„±
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, embedding_dim)
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Linear(embedding_dim, 1)
    
    def forward(self, user_features, item_features):
        # ì‚¬ìš©ìì™€ ì•„ì´í…œ ì„ë² ë”© ìƒì„±
        user_embedding = self.user_tower(user_features)
        item_embedding = self.item_tower(item_features)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        user_norm = F.normalize(user_embedding, p=2, dim=1)
        item_norm = F.normalize(item_embedding, p=2, dim=1)
        
        # ë‚´ì  ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë™ì¼)
        similarity = torch.sum(user_norm * item_norm, dim=1, keepdim=True)
        
        # ì¶œë ¥ ë ˆì´ì–´ë¥¼ í†µê³¼í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡
        output = self.output_layer(similarity)
        
        return output


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    from .vector_database import MusicVectorDatabase
    from .spotify_collector import SpotifyMusicCollector
    
    # ì´ˆê¸°í™”
    vector_db = MusicVectorDatabase()
    spotify_collector = SpotifyMusicCollector()
    recommender = MusicRecommender(vector_db, spotify_collector)
    
    # ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ê°€ (ì˜ˆì‹œ)
    recommender.add_user_preference("user1", "track_id_1", 5.0)
    recommender.add_user_preference("user1", "track_id_2", 4.0)
    
    # ì¶”ì²œ ë°›ê¸°
    print("\n=== ê¸°ë³¸ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ===")
    recommendations = recommender.recommend_music("user1", n_recommendations=5, method="hybrid")
    
    print(f"Found {len(recommendations)} recommendations:")
    for rec in recommendations:
        print(f"- {rec['name']} by {rec['artists']}")
        if 'method' in rec:
            print(f"  Method: {rec['method']}")
    
    print("\n=== Two-Stage ì¶”ì²œ ì‹œìŠ¤í…œ ===")
    two_stage_recommendations = recommender.recommend_music("user1", n_recommendations=5, method="two_stage")
    
    print(f"Found {len(two_stage_recommendations)} two-stage recommendations:")
    for rec in two_stage_recommendations:
        print(f"- {rec['name']} by {rec['artists']}")
        if 'two_stage_score' in rec:
            print(f"  Two-Stage Score: {rec['two_stage_score']:.3f}")
        if 'method' in rec:
            print(f"  Method: {rec['method']}")
    
    # ì„ í˜¸ë„ ì €ì¥
    recommender.save_user_preferences()
